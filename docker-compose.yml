services:
  # 模型下載服務（第一次啟動會下載模型檔案，完成後容器保持停止狀態）
  model-downloader:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-model-downloader
    volumes:
      - ./backend:/app
    command: >
      sh -c "
        set -e
        MODEL_PATH=/app/models/inswapper_128.onnx
        mkdir -p /app/models

        if [ -f \"$$MODEL_PATH\" ]; then
          echo '✅ AI 模型已存在，跳過下載'
          FILE_SIZE=$$(stat -c%s \"$$MODEL_PATH\" 2>/dev/null || echo \"0\")
          FILE_SIZE=$${FILE_SIZE:-0}
          echo \"📊 現有檔案大小: $$FILE_SIZE bytes\"
          ls -lh \"$$MODEL_PATH\"
          exit 0
        fi

        echo '🔄 正在下載 AI 模型檔案...'

        download_from() {
          URL=\$$1
          SOURCE_LABEL=\$$2
          echo \"📥 嘗試從 \$$SOURCE_LABEL 下載...\"
          if wget --timeout=60 --tries=3 --progress=bar:force:noscroll -O \"\$$MODEL_PATH\" \"\$$URL\"; then
            return 0
          else
            return 1
          fi
        }

        download_from 'https://huggingface.co/spaces/mkrzyzan/face-swap/resolve/main/inswapper_128.onnx' 'HuggingFace' || \
        download_from 'https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128.onnx' 'GitHub'

        if [ ! -f \"$$MODEL_PATH\" ]; then
          echo '❌ 模型檔案下載失敗'
          exit 1
        fi

        FILE_SIZE=$$(stat -c%s \"$$MODEL_PATH\" 2>/dev/null || echo \"0\")
        FILE_SIZE=$${FILE_SIZE:-0}
        echo \"📊 下載檔案大小: $$FILE_SIZE bytes\"

        if [ $$FILE_SIZE -lt 200000000 ]; then
          echo '❌ 檔案太小，可能下載不完整'
          rm -f \"$$MODEL_PATH\"
          exit 1
        fi

        if python3 -c \"import onnx; onnx.load('$$MODEL_PATH')\" 2>/dev/null; then
          echo '✅ 模型檔案驗證完成'
        else
          echo '⚠️ 無法驗證 ONNX 格式，但檔案大小正常'
        fi

        ls -lh \"$$MODEL_PATH\"
      "
    restart: "no"

  redis:
    image: redis:7-alpine
    container_name: ai-face-swap-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: >
      redis-server
      --appendonly yes
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --tcp-backlog 2048
      --timeout 0
      --tcp-keepalive 300
      --maxclients 10000
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  frontend:
    image: docker.io/library/nginx:alpine
    container_name: ai-face-swap-frontend
    ports:
      - "8882:80"
    volumes:
      - ./frontend:/usr/share/nginx/html
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./backend/results:/results:ro
      - ./backend/uploads:/uploads:ro
    depends_on:
      - backend
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-backend
    expose:
      - "3001"
    volumes:
      # 一次全掛載整個後端目錄
      - ./backend:/app
    depends_on:
      redis:
        condition: service_healthy
      model-downloader:
        condition: service_completed_successfully
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    environment:
      - PYTHONPATH=/app
      - ENVIRONMENT=development
      - SERVICE_ROLE=api
      - REDIS_URL=redis://redis:6379/0
    privileged: true
    # 啟動 uvicorn，高併發優化 (支援 4000+ 並發任務)
    command: [
      "python", "-m", "uvicorn", "app:app",
      "--host", "0.0.0.0",
      "--port", "3001",
      "--workers", "8",
      "--backlog", "4096",
      "--timeout-keep-alive", "120",
      "--limit-max-requests", "0",
      "--limit-concurrency", "5000",
      "--log-level", "warning"
    ]

  # Worker 容器已停用 - 改用 Backend API 的 asyncio.create_task 處理任務
  # 優點: 減少 Redis 佇列延遲，提升高 QPS 性能
  # worker:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   container_name: ai-face-swap-worker
  #   volumes:
  #     - ./backend:/app
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #     model-downloader:
  #       condition: service_completed_successfully
  #   restart: unless-stopped
  #   environment:
  #     - PYTHONPATH=/app
  #     - ENVIRONMENT=development
  #     - SERVICE_ROLE=worker
  #     - REDIS_URL=redis://redis:6379/0
  #   privileged: true
  #   command: [
  #     "python",
  #     "worker.py"
  #   ]

volumes:
  redis-data:

networks:
  default:
    name: ai-avatar-studio-network
