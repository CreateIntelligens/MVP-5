services:
  # Ê®°Âûã‰∏ãËºâÊúçÂãôÔºàÁ¨¨‰∏ÄÊ¨°ÂïüÂãïÊúÉ‰∏ãËºâÊ®°ÂûãÊ™îÊ°àÔºåÂÆåÊàêÂæåÂÆπÂô®‰øùÊåÅÂÅúÊ≠¢ÁãÄÊÖãÔºâ
  model-downloader:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-model-downloader
    volumes:
      - ./backend:/app
    command: >
      sh -c "
        set -e
        MODEL_PATH=/app/models/inswapper_128.onnx
        mkdir -p /app/models

        if [ -f \"$$MODEL_PATH\" ]; then
          echo '‚úÖ AI Ê®°ÂûãÂ∑≤Â≠òÂú®ÔºåË∑≥ÈÅé‰∏ãËºâ'
          FILE_SIZE=$$(stat -c%s \"$$MODEL_PATH\" 2>/dev/null || echo \"0\")
          FILE_SIZE=$${FILE_SIZE:-0}
          echo \"üìä ÁèæÊúâÊ™îÊ°àÂ§ßÂ∞è: $$FILE_SIZE bytes\"
          ls -lh \"$$MODEL_PATH\"
          exit 0
        fi

        echo 'üîÑ Ê≠£Âú®‰∏ãËºâ AI Ê®°ÂûãÊ™îÊ°à...'

        download_from() {
          URL=\$$1
          SOURCE_LABEL=\$$2
          echo \"üì• ÂòóË©¶Âæû \$$SOURCE_LABEL ‰∏ãËºâ...\"
          if wget --timeout=60 --tries=3 --progress=bar:force:noscroll -O \"\$$MODEL_PATH\" \"\$$URL\"; then
            return 0
          else
            return 1
          fi
        }

        download_from 'https://huggingface.co/spaces/mkrzyzan/face-swap/resolve/main/inswapper_128.onnx' 'HuggingFace' || \
        download_from 'https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128.onnx' 'GitHub'

        if [ ! -f \"$$MODEL_PATH\" ]; then
          echo '‚ùå Ê®°ÂûãÊ™îÊ°à‰∏ãËºâÂ§±Êïó'
          exit 1
        fi

        FILE_SIZE=$$(stat -c%s \"$$MODEL_PATH\" 2>/dev/null || echo \"0\")
        FILE_SIZE=$${FILE_SIZE:-0}
        echo \"üìä ‰∏ãËºâÊ™îÊ°àÂ§ßÂ∞è: $$FILE_SIZE bytes\"

        if [ $$FILE_SIZE -lt 200000000 ]; then
          echo '‚ùå Ê™îÊ°àÂ§™Â∞èÔºåÂèØËÉΩ‰∏ãËºâ‰∏çÂÆåÊï¥'
          rm -f \"$$MODEL_PATH\"
          exit 1
        fi

        if python3 -c \"import onnx; onnx.load('$$MODEL_PATH')\" 2>/dev/null; then
          echo '‚úÖ Ê®°ÂûãÊ™îÊ°àÈ©óË≠âÂÆåÊàê'
        else
          echo '‚ö†Ô∏è ÁÑ°Ê≥ïÈ©óË≠â ONNX Ê†ºÂºèÔºå‰ΩÜÊ™îÊ°àÂ§ßÂ∞èÊ≠£Â∏∏'
        fi

        ls -lh \"$$MODEL_PATH\"
      "
    restart: "no"

  redis:
    image: redis:7-alpine
    container_name: ai-face-swap-redis
    restart: unless-stopped
    expose:
      - "6379"
    volumes:
      - redis-data:/data
    command: redis-server
      --appendonly yes
      --maxmemory 4gb
      --maxmemory-policy allkeys-lru
      --tcp-backlog 2048
      --timeout 300
      --tcp-keepalive 60
      --maxclients 25000
      --hz 100
      --databases 16
    deploy:
      resources:
        reservations:
          memory: 3G
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  frontend:
    image: docker.io/library/nginx:alpine
    container_name: ai-face-swap-frontend
    ports:
      - "8882:80"
    volumes:
      - ./frontend:/usr/share/nginx/html
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./backend/results:/results:ro
      - ./backend/uploads:/uploads:ro
    depends_on:
      - backend
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-backend
    expose:
      - "3001"
    volumes:
      - ./backend:/app
    depends_on:
      redis:
        condition: service_healthy
      model-downloader:
        condition: service_completed_successfully
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          memory: 2G
    environment:
      - PYTHONPATH=/app
      - ENVIRONMENT=development
      - SERVICE_ROLE=api
      - REDIS_URL=redis://redis:6379/0
      - MAX_QUEUE_SIZE=${MAX_QUEUE_SIZE:-2000}
      - ENABLE_QUEUE_LIMIT=${ENABLE_QUEUE_LIMIT:-true}
      - TZ=Asia/Taipei
    privileged: true
    # API Â±§Â§ö workerÔºåÁ¥îÊéíÈöäËàáÊü•Ë©¢
    command: [
      "python", "-m", "uvicorn", "app:app",
      "--host", "0.0.0.0",
      "--port", "3001",
      "--workers", "8",
      "--backlog", "65535",
      "--timeout-keep-alive", "600",
      "--log-level", "warning"
    ]

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-worker
    volumes:
      - ./backend:/app
    depends_on:
      redis:
        condition: service_healthy
      model-downloader:
        condition: service_completed_successfully
      backend:
        condition: service_started
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          memory: 8G
    environment:
      - PYTHONPATH=/app
      - ENVIRONMENT=development
      - SERVICE_ROLE=worker
      - REDIS_URL=redis://redis:6379/0
      - TZ=Asia/Taipei
    privileged: true
    command: [
      "python",
      "worker.py"
    ]

volumes:
  redis-data:

networks:
  default:
    name: ai-avatar-studio-network
