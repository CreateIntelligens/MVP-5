services:
  # æ¨¡å‹ä¸‹è¼‰æœå‹™ï¼ˆç¬¬ä¸€æ¬¡å•Ÿå‹•æœƒä¸‹è¼‰æ¨¡å‹æª”æ¡ˆï¼Œå®Œæˆå¾Œå®¹å™¨ä¿æŒåœæ­¢ç‹€æ…‹ï¼‰
  model-downloader:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-model-downloader
    volumes:
      - ./backend:/app
    command: >
      sh -c "
        set -e
        MODEL_PATH=/app/models/inswapper_128.onnx
        mkdir -p /app/models

        if [ -f \"$$MODEL_PATH\" ]; then
          echo 'âœ… AI æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰'
          FILE_SIZE=$$(stat -c%s \"$$MODEL_PATH\" 2>/dev/null || echo \"0\")
          FILE_SIZE=$${FILE_SIZE:-0}
          echo \"ğŸ“Š ç¾æœ‰æª”æ¡ˆå¤§å°: $$FILE_SIZE bytes\"
          ls -lh \"$$MODEL_PATH\"
          exit 0
        fi

        echo 'ğŸ”„ æ­£åœ¨ä¸‹è¼‰ AI æ¨¡å‹æª”æ¡ˆ...'

        download_from() {
          URL=$$1
          SOURCE_LABEL=$$2
          echo \"ğŸ“¥ å˜—è©¦å¾ $$SOURCE_LABEL ä¸‹è¼‰...\"
          if wget --timeout=60 --tries=3 --progress=bar:force:noscroll -O \"$$MODEL_PATH\" \"$$URL\"; then
            return 0
          fi
          return 1
        }

        download_from 'https://huggingface.co/spaces/mkrzyzan/face-swap/resolve/main/inswapper_128.onnx' 'HuggingFace' || \
        download_from 'https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128.onnx' 'GitHub'

        if [ ! -f \"$$MODEL_PATH\" ]; then
          echo 'âŒ æ¨¡å‹æª”æ¡ˆä¸‹è¼‰å¤±æ•—'
          exit 1
        fi

        FILE_SIZE=$$(stat -c%s \"$$MODEL_PATH\" 2>/dev/null || echo \"0\")
        FILE_SIZE=$${FILE_SIZE:-0}
        echo \"ğŸ“Š ä¸‹è¼‰æª”æ¡ˆå¤§å°: $$FILE_SIZE bytes\"

        if [ $$FILE_SIZE -lt 200000000 ]; then
          echo 'âŒ æª”æ¡ˆå¤ªå°ï¼Œå¯èƒ½ä¸‹è¼‰ä¸å®Œæ•´'
          rm -f \"$$MODEL_PATH\"
          exit 1
        fi

        if python3 -c \"import onnx; onnx.load('$$MODEL_PATH')\" 2>/dev/null; then
          echo 'âœ… æ¨¡å‹æª”æ¡ˆé©—è­‰å®Œæˆ'
        else
          echo 'âš ï¸ ç„¡æ³•é©—è­‰ ONNX æ ¼å¼ï¼Œä½†æª”æ¡ˆå¤§å°æ­£å¸¸'
        fi

        ls -lh \"$$MODEL_PATH\"
      "
    restart: "no"

  frontend:
    image: docker.io/library/nginx:alpine
    container_name: ai-face-swap-frontend
    ports:
      - "8882:80"
    volumes:
      - ./frontend:/usr/share/nginx/html
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./backend/results:/results:ro
      - ./backend/uploads:/uploads:ro
    depends_on:
      - backend
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-face-swap-backend
    expose:
      - "3001"
    volumes:
      # ä¸€æ¬¡å…¨æ›è¼‰æ•´å€‹å¾Œç«¯ç›®éŒ„
      - ./backend:/app
    depends_on:
      - model-downloader
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    environment:
      - PYTHONPATH=/app
      - ENVIRONMENT=development
    privileged: true
    # å•Ÿå‹• uvicornï¼Œèª¿æ•´ backlog èˆ‡ keep-alive ä»¥æå‡é«˜ä½µç™¼é€£ç·šèƒ½åŠ›
    command: [
      "python", "-m", "uvicorn", "app:app",
      "--host", "0.0.0.0",
      "--port", "3001",
      "--workers", "1",
      "--backlog", "65535",
      "--timeout-keep-alive", "600",
      "--limit-max-requests", "100000",
      "--log-level", "warning"
    ]

networks:
  default:
    name: ai-avatar-studio-network
